{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07629a16-c3e1-487f-a170-503189c4dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart.csv')\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df['target'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "1.\tRealizar un análisis exploratorio de los datos para identificar relaciones entre variables, valores atípicos, tendencias, etc. \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matriz de correlación\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Distribución de la variable objetivo\n",
    "sns.countplot(data=df, x='target')\n",
    "plt.show()\n",
    "2.\tPreprocesar los datos limpiándolos, tratando valores faltantes y transformándolos según sea necesario. \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# One Hot Encoding para variables categóricas\n",
    "df = pd.get_dummies(df, columns=['sex', 'cp', 'slope', 'thal'], drop_first=True)\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "columnas_numericas = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "df[columnas_numericas] = scaler.fit_transform(df[columnas_numericas])\n",
    "3.\tSeleccionar las características más relevantes para entrenar el modelo utilizando selección de características.\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Selección de las mejores características\n",
    "selector = SelectKBest(chi2, k=10)\n",
    "selector.fit(X, y)\n",
    "X_seleccionado = selector.transform(X)\n",
    "4.\tDividir el dataset en Train y Test para evaluar correctamente elmodelo.}\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seleccionado, y, test_size=0.2, random_state=42)\n",
    "5.\tEntrenar el modelo configurando los diferentes hiperparámetros. \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "parametros = {'C': [0.1, 1, 10], 'penalty': ['l2']}\n",
    "grid = GridSearchCV(modelo, parametros, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "mejor_modelo = grid.best_estimator_\n",
    "6.\tEvaluar el desempeño del modelo en el conjunto de Test con métricas como precisión, recall, F1-score, etc.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = mejor_modelo.predict(X_test)\n",
    "y_proba = mejor_modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Cálculo de métricas\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred)}')\n",
    "print(f'ROC AUC: {roc_auc_score(y_test, y_proba)}')\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.plot(fpr, tpr, label='Regresión Logística')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "7.\tRealizar las diferentes gráficas que permitan visualizar los resultados del modelo.\n",
    "\n",
    "8.\tInterpretar, analizar y documentar los resultados obtenidos.\n",
    "\n",
    "Análisis Exploratorio de Datos\n",
    "El análisis inicial del dataset muestra cómo algunas variables tienen una relación significativa con la presencia de enfermedad cardíaca (variable objetivo target). Las características como age (edad), chol (colesterol), thalach (máxima frecuencia cardíaca alcanzada), y trestbps (presión sanguínea en reposo) están correlacionadas con la enfermedad cardíaca, sugiriendo que estos factores pueden influir en la probabilidad de padecerla.\n",
    "________________________________________\n",
    "2. Preprocesamiento y Selección de Características\n",
    "El preprocesamiento incluyó la codificación de variables categóricas y el escalado de características numéricas, lo cual fue esencial para asegurar que todas las variables estén en una escala comparable y que el modelo de regresión logística funcione de manera óptima. Además, se seleccionaron las variables más relevantes, evitando el uso de datos menos influyentes o redundantes, lo que optimiza el rendimiento y la eficiencia del modelo.\n",
    "________________________________________\n",
    "3. Rendimiento del Modelo\n",
    "El modelo de regresión logística entrenado se evaluó con las siguientes métricas:\n",
    "•\tExactitud (Accuracy): La precisión del modelo en clasificar correctamente los casos de enfermedad cardíaca y los casos sin enfermedad. Un valor alto indica que el modelo predice correctamente la mayoría de los casos en el conjunto de prueba.\n",
    "•\tPrecisión (Precision): Mide la proporción de casos positivos predichos correctamente sobre el total de casos predichos como positivos. Alta precisión significa que el modelo tiene una baja tasa de falsos positivos.\n",
    "•\tRecall (Sensibilidad): Indica la capacidad del modelo para identificar todos los casos verdaderamente positivos. Es crucial para la identificación de casos de enfermedad cardíaca, ya que una alta sensibilidad significa que el modelo detecta la mayoría de los pacientes que realmente tienen la enfermedad.\n",
    "•\tF1 Score: Combina precisión y sensibilidad en una métrica única. Un valor alto de F1 indica que el modelo mantiene un buen equilibrio entre precisión y sensibilidad, siendo útil cuando hay un desbalance en las clases.\n",
    "•\tROC AUC (Área bajo la curva ROC): Refleja la capacidad del modelo para distinguir entre pacientes con y sin enfermedad cardíaca. Un valor cercano a 1 indica una excelente capacidad de discriminación, lo que sugiere que el modelo es confiable en la identificación de casos de riesgo.\n",
    "________________________________________\n",
    "4. Conclusión\n",
    "El modelo de regresión logística demuestra un buen rendimiento al predecir la presencia de enfermedad cardíaca en el conjunto de prueba. Las métricas obtenidas indican que el modelo tiene un buen balance entre la precisión y la sensibilidad, lo cual es valioso en aplicaciones médicas, donde es esencial reducir tanto los falsos positivos como los falsos negativos.\n",
    "•\tInterpretación clínica: Este modelo puede ser útil para ayudar a los médicos en la evaluación de riesgos cardíacos, identificando con eficacia a los pacientes que necesitan más estudios o intervenciones tempranas.\n",
    "•\tAplicabilidad: Aunque el modelo es efectivo, podría beneficiarse de la integración de más datos de pacientes o características adicionales que capturen otros factores de riesgo, como la dieta, los niveles de ejercicio o el historial familiar, para mejorar la precisión y utilidad clínica del modelo.\n",
    "En general, este análisis y el modelo desarrollado apoyan una herramienta diagnóstica que puede ser útil para predecir riesgos cardíacos, contribuyendo a la prevención y atención temprana en pacientes propensos a enfermedades del corazón.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
